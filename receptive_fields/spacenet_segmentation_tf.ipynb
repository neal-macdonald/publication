{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WZKbyU2-AiY-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "tf.__version__\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_models import create_unet, create_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_folder = r\"\" # Data containing spacenet \n",
    "out_folder = r\"\" # Set to desired output folder location\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "IMAGE_SIZE = (256,256)\n",
    "RANDOM_SEED = 101\n",
    "KERNELS = [3,5,7]\n",
    "DILATIONS = [1,2,3]\n",
    "WEIGHTS = [\"GlorotNormal\",\"NovelMethod\",]\n",
    "combinations = list(itertools.product(KERNELS,DILATIONS,WEIGHTS))\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "if not os.path.isdir(out_folder):\n",
    "    os.mkdir(out_folder)\n",
    "data_dir = pathlib.Path(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(23028, shape=(), dtype=int64) tf.Tensor(17028, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('images/*.jpg')))\n",
    "images_ds = tf.data.Dataset.list_files(str(data_dir/'images/*'), shuffle=False)\n",
    "labels_ds = tf.data.Dataset.list_files(str(data_dir/'labels/*'), shuffle=False)\n",
    "dataset = tf.data.Dataset.zip((images_ds, labels_ds))\n",
    "dataset = dataset.shuffle(image_count, seed = RANDOM_SEED, reshuffle_each_iteration=False)\n",
    "val_size = 5000\n",
    "test_size = 1000\n",
    "train_ds = dataset.skip(val_size+test_size)\n",
    "val_ds = dataset.skip(test_size).take(val_size)\n",
    "test_ds = dataset.take(test_size)\n",
    "print(dataset.cardinality(),train_ds.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(img_path,lab_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMAGE_SIZE)\n",
    "    img = tf.keras.layers.Rescaling(1./255)(img)\n",
    "    lab = tf.io.read_file(lab_path)\n",
    "    lab = tf.io.decode_jpeg(lab, channels=1)\n",
    "    lab = tf.image.resize(lab, IMAGE_SIZE)\n",
    "    return img, lab\n",
    "train_ds_mapped = train_ds.map(process_data,num_parallel_calls=AUTOTUNE)\n",
    "val_ds_mapped = val_ds.map(process_data,num_parallel_calls=AUTOTUNE)\n",
    "test_ds_mapped = test_ds.map(process_data,num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=(image_count+1000),reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "train_ds_ready = configure_for_performance(train_ds_mapped)\n",
    "val_ds_ready = configure_for_performance(val_ds_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# def iou(y_true, y_pred):\n",
    "#     ''' Adapted from https://github.com/IdanC1s2/Spacenet-Building-Detection/blob/431129537fac0f9b98393bdd520e4b032f05c453/Models/Train_Model3Band.py '''\n",
    "#     y_true_f = K.cast(K.flatten(y_true), dtype='float32')\n",
    "#     y_pred_f = K.cast(K.flatten(y_pred), dtype='float32')\n",
    "#     intersection = K.sum(y_true_f * y_pred_f)\n",
    "#     return (intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + K.epsilon())\n",
    "\n",
    "# def iou_loss(y_true, y_pred):\n",
    "#     return -iou(y_true, y_pred)\n",
    "\n",
    "def iou_hard(y_true, y_pred):\n",
    "    y_true_f = K.cast(K.greater(K.flatten(y_true), 0.5), dtype='float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), dtype='float32')\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + K.epsilon())\n",
    "\n",
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for KERNEL, DILATION, WEIGHT in combinations:\n",
    "    print(KERNEL, DILATION, WEIGHT)\n",
    "    model = create_unet(IMAGE_SIZE+(3,), KERNEL, DILATION, WEIGHT)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(), metrics=[f1,iou_hard])\n",
    "    model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_f1', patience=10, min_delta = 0.0001, mode='max', restore_best_weights=True)\n",
    "    history_1 = model.fit(x=train_ds_ready, validation_data=val_ds_ready, epochs=EPOCHS, callbacks=[model_early_stopping])\n",
    "    test_loss, test_f1, test_iou_hard = model.evaluate(test_ds_mapped.batch(BATCH_SIZE))\n",
    "    hist_df = pd.DataFrame(history_1.history)\n",
    "    hist_df.loc[\"Test\"] = [0,0,0, test_loss, test_f1, test_iou_hard]\n",
    "    hist_df.to_csv(os.path.join(out_folder,f\"history_k{KERNEL}_d{DILATION}_{WEIGHT}.csv\"))\n",
    "\n",
    "    test_preds = model.predict(test_ds_mapped.batch(BATCH_SIZE))\n",
    "    names = [tf.strings.split(f, os.path.sep)[-1][-1].numpy() for f in test_ds.take(test_size)]\n",
    "    folder_path = os.path.join(out_folder,f\"k{KERNEL}_d{DILATION}_{WEIGHT}\")\n",
    "    if not os.path.isdir(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    for name, test in zip(names, test_preds):\n",
    "        file_path = os.path.join(folder_path,f\"pred_{os.path.splitext(name.decode())[0]}.npy\")\n",
    "        np.save(file_path, test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m96"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
