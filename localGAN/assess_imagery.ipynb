{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5ce6b5-c4c0-4032-8807-7c2e8575b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ranksums,ttest_rel,wilcoxon\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26bf7de6-b81f-4e9c-9491-fa57bd088457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import process_unknown, predict_unknown, unsup_and_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b383af-89d4-4c87-98ad-6e8bee0925ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_folder = r\"\" # Folder where unsupervised clustering results are stored.\n",
    "testing_data = r\"\" # Folder where testing data is stored\n",
    "fine_tune_folder = r\"\" # Folder where fine-tuned data is stored\n",
    "original_model = r\"\" # Desired checkpoint file from 'gan_training'\n",
    "supervised_model = r\"\" # Supervised model from 'supervised_cluster_cnn'\n",
    "\n",
    "SHAPE = [476,476,3]\n",
    "number_samples = 50    # Number of samples to take from each test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2f12d-fe0c-456f-8901-61c5261e8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = os.path.join(testing_data,\"real_images\")\n",
    "fake_path = os.path.join(testing_data,\"generated_images\")\n",
    "dalle_path = os.path.join(testing_data,\"DALLE imagery\")\n",
    "paths = [real_path,fake_path,dalle_path]\n",
    "\n",
    "outlist = []\n",
    "for path, subdirs, files in os.walk(clustering_folder):\n",
    "    for sub in subdirs:\n",
    "        class_folder = os.path.join(path,sub)\n",
    "        i = 0\n",
    "        for name in os.listdir(class_folder):\n",
    "            if i<number_samples:\n",
    "                outlist.append(os.path.join(path, sub, name))\n",
    "                i+=1\n",
    "            else:\n",
    "                break\n",
    "output = {}\n",
    "for classx in range(18):\n",
    "    class_holding = []\n",
    "    for file in outlist:\n",
    "        if file.split('\\\\')[-2] == f'class_{classx}':\n",
    "            class_holding.append(file)\n",
    "    count = sum([unsup_and_sup(file,supervised_model) for file in class_holding])\n",
    "    output[classx] = count/number_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4e1a7-d13b-4b4a-952a-2e002aa39d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "bar_container = ax.bar([x+1 for x in list(output.keys())],[v*100 for v in output.values()],color=(0.2, 0.4, 0.6, 0.6))\n",
    "ax.bar_label(bar_container, fmt='%2.f%%');\n",
    "ax.set_xticks([x for x in range(1,19)]);\n",
    "ax.set_xlabel(\"Class Number\",fontsize=12);\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.title(\"Percentage of Top-3 Supervised Predictions of Unsupervised Class Label\")\n",
    "plt.savefig('x50_unsuptest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d17330-fd00-48c0-802c-02a7da393555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import plot_partial_dependence\n",
    "# disp=plot_partial_dependence(lstm_model, X_train, target=1, verbose =1, features=[0,1,2,3,4],feature_names=f_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4f3b1-4502-43ac-bbb0-0a046035f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather class-specific models\n",
    "def assess(folder):\n",
    "    \n",
    "    files = []\n",
    "    for r, d, f in os.walk(os.path.abspath(folder)):\n",
    "        for file in f:\n",
    "            files.append(os.path.join(r, file)) \n",
    "    \n",
    "    output = {}\n",
    "    processed = process_unknown(files,supervised_model)\n",
    "    # print(processed)\n",
    "    for name, class_predictions in processed.items():\n",
    "        result,weight = [],[]\n",
    "        for class_match, percentage in class_predictions.items():\n",
    "            model = os.path.join(fine_tune_folder,rf\"ft_class_{class_match}\\class_{class_match}_ft-1\")\n",
    "            try:\n",
    "                predict = predict_unknown(os.path.join(folder,name),model,SHAPE)\n",
    "                result.append(predict*percentage)\n",
    "                weight.append(percentage)\n",
    "                # print(class_match,predict,percentage)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        original_prediction = predict_unknown(os.path.join(folder,name),original_model,SHAPE)\n",
    "        output[name] = {'original':np.round(original_prediction,3), \"fine tuned\":np.round(sum(result)/(sum(weight)+0.000001),3)}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bcb629-3aae-413b-8085-7d5770b077b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [assess(path) for path in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2a332-833f-494c-8aa1-754cf3e93f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "holding = []\n",
    "for i,f in enumerate(results):\n",
    "    dfx = pd.DataFrame.from_dict(f,'index')\n",
    "    dfx['difference'] = (dfx['fine tuned']-dfx['original'])\n",
    "    print(np.mean(dfx['original']),np.mean(dfx['fine tuned']))\n",
    "    # print(ttest_rel(dfx['original'],dfx['fine tuned']))\n",
    "    # print(wilcoxon(dfx['original'],dfx['fine tuned'],alternative='two-sided'))\n",
    "    if i == 0:\n",
    "        print(wilcoxon(dfx['original'],dfx['fine tuned'],alternative='less'))\n",
    "        print(wilcoxon(dfx['original'],dfx['fine tuned'],alternative='two-sided'))\n",
    "    else:\n",
    "        print(wilcoxon(dfx['original'],dfx['fine tuned'],alternative='greater'))\n",
    "        print(wilcoxon(dfx['original'],dfx['fine tuned'],alternative='two-sided'))\n",
    "    print(np.mean(dfx['difference']),'\\n')\n",
    "    holding.append(dfx)\n",
    "df = pd.concat(holding,axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146923b7-95db-41be-a82d-b9dcf013d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('x200_with_2.0_wilcoxon.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
