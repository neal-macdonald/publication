{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f62df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "tf.__version__\n",
    "\n",
    "import os, sys\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pathlib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.manifold import TSNE\n",
    "import skimage\n",
    "import scipy\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797a0cd-82d5-42fd-aaea-089c4f6c9fc2",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cdc1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25\n",
    "\n",
    "latent_dim = 1024\n",
    "num_classes = 18\n",
    "\n",
    "RANDOM_SEED = 101\n",
    "random.seed(RANDOM_SEED)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "val_size = BATCH_SIZE*16\n",
    "test_size = num_classes*25\n",
    "\n",
    "input_folder = r\"\" # Set to GEE Imagery Folder on local computer\n",
    "weights_folder = r\"\" # Folder where model weights should be saved\n",
    "clustering_folder = r\"\" # Folder to save clustering results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9d353-1e5a-416f-8ada-88be5be255d5",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(input_folder,item) for item in os.listdir(input_folder) if item.endswith('.tif')]\n",
    "random.seed(101)\n",
    "random.shuffle(files)\n",
    "SHAPE = [256,256,6] #get_smallest_img(files) \n",
    "# SHAPE[0], SHAPE[1] = min(SHAPE[0],SHAPE[1]), min(SHAPE[0],SHAPE[1])\n",
    "print(\"Smallest image in set:\", SHAPE)\n",
    "\n",
    "image_count = len(list(pathlib.Path(input_folder).glob('*.tif')))\n",
    "print(f\"{image_count} total images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ce08c-4993-4653-940c-0f0aa8955835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self,files_list,shape,num_classes=0,categorize=False,unsupervised=False,mean=0.5):\n",
    "        self.files = copy.deepcopy(files_list)\n",
    "        self.shape = shape\n",
    "        self.categorize = categorize\n",
    "        self.unsupervised = unsupervised\n",
    "        self.mean = mean\n",
    "        self.num_classes = num_classes\n",
    "        random.shuffle(self.files)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def data_augmentation(self,image):\n",
    "        steps = keras.Sequential(\n",
    "                [keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "                 keras.layers.RandomRotation(0.3),\n",
    "                 keras.layers.RandomZoom(0.1),\n",
    "                 keras.layers.RandomCrop(SHAPE[0], SHAPE[1])])\n",
    "        return steps(image)\n",
    "    \n",
    "    def parse_image(self,filename,mean=0.5):\n",
    "        try:\n",
    "            image = skimage.io.imread(filename)[:,:,:self.shape[2]]\n",
    "            # image = tf.convert_to_tensor(image)\n",
    "            # image = self.data_augmentation(image)\n",
    "            image = tf.image.resize_with_crop_or_pad(image,self.shape[0], self.shape[1])\n",
    "            image = tf.image.per_image_standardization(image)\n",
    "            if self.mean == 0.5:\n",
    "                image = tf.math.divide(tf.math.add(image,tf.math.abs(tf.math.reduce_min(image))),tf.math.add(tf.math.reduce_max(image),tf.math.abs(tf.math.reduce_min(image)))+0.00001)\n",
    "            return image\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        file = self.files[idx]\n",
    "        image = self.parse_image(file)\n",
    "        if self.categorize == False:\n",
    "            if self.unsupervised == False:\n",
    "                return image\n",
    "            else:\n",
    "                return image,image\n",
    "        else:\n",
    "            onehot = tf.one_hot(range(self.num_classes), self.num_classes)\n",
    "            category = int(os.path.split(os.path.split(file)[0])[1].split('_')[1])\n",
    "            hot_label = onehot[int(category)]\n",
    "            return image, hot_label\n",
    "\n",
    "    def __call__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "            if i == self.__len__()-1:\n",
    "                self.on_epoch_end()    \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.files)\n",
    "\n",
    "ds_series = tf.data.Dataset.from_generator(DataGenerator(files,SHAPE,unsupervised=True),\n",
    "                                           output_shapes=(SHAPE,SHAPE),\n",
    "                                           output_types=(tf.float32,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849c8c6-dceb-438b-9d10-ea37dd27261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 20))\n",
    "# for i,image in enumerate(ds_series.take(64)):\n",
    "#     plt.subplot(8, 8, i + 1)\n",
    "#     plt.imshow(image[0][:,:,:3])\n",
    "#     plt.axis(\"off\")\n",
    "# plt.subplots_adjust(hspace=0.01, wspace=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e3e36-229a-447c-9755-079649a9de80",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ff3b5-a74c-43bc-b7ce-f10ce7641eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_image(filename):\n",
    "#     img = skimage.io.imread(filename)\n",
    "#     img = tf.convert_to_tensor(img)\n",
    "#     img = tf.image.per_image_standardization(img)\n",
    "#     img = tf.image.resize_with_crop_or_pad(img,SHAPE[0], SHAPE[1]).numpy()\n",
    "#     img = np.divide(np.add(img,np.abs(img.min())),np.add(img.max(),np.abs(img.min()))+0.00001)\n",
    "#     return img\n",
    "\n",
    "# singulars = []\n",
    "# pca = PCA(6)\n",
    "# for file in tqdm(files):\n",
    "#     image = parse_image(file) \n",
    "#     image = np.reshape(image,(image.shape[0]*image.shape[1],image.shape[2]))\n",
    "#     singulars.append(pca.fit(image).singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d4fd33-3988-4a30-a42e-d9572a7b8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criteria = (cv2.TERM_CRITERIA_EPS, -1, 1.0)\n",
    "# compactness, labels, _ = cv2.kmeans(np.stack(singulars), num_classes, None, criteria, 100, cv2.KMEANS_RANDOM_CENTERS)\n",
    "# average_distance_from_each_label_center = compactness / float(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c061d-15a6-41e2-a330-31b7b36c9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histo = np.histogram(labels,np.unique(labels))\n",
    "# plt.bar(histo[1][1:],histo[0]);\n",
    "# plt.xticks(np.unique(labels));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1795a8-b712-4b27-b3a6-b4001782f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# cluster_output_save_path = os.path.join(clustering_folder,\"Image Generator spectral cluster\")\n",
    "# for file,label in zip(files,labels):  \n",
    "#     save_dir = rf'{cluster_output_save_path}\\class_{str(label[0])}'\n",
    "#     if not (os.path.exists(save_dir) and os.path.isdir(save_dir)):\n",
    "#         os.makedirs(save_dir, exist_ok=True)\n",
    "#     basename = os.path.basename(file)\n",
    "#     shutil.copy2(file, rf'{save_dir}\\{basename}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5279ab4-8a54-4127-9e00-54d014133c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_rows = 10\n",
    "# plt.figure(figsize=(20, 50))\n",
    "# for col in range(num_classes):\n",
    "#     class_folder = os.path.join(cluster_output_save_path,f\"class_{col}\")\n",
    "#     class_files = os.listdir(class_folder)\n",
    "#     random.shuffle(class_files)\n",
    "#     for i in range(num_rows): \n",
    "#         try:\n",
    "#             img = skimage.io.imread(os.path.join(cluster_output_save_path,f\"class_{col}\",class_files[i]))[:,:,:3]\n",
    "#             ax = plt.subplot(num_classes, num_rows, col*num_rows + i + 1)\n",
    "#             plt.imshow(img,aspect=\"auto\")\n",
    "#             plt.axis(\"off\")\n",
    "#         except:\n",
    "#             pass\n",
    "# plt.subplots_adjust(hspace=0.1, wspace=0.01)\n",
    "# # plt.savefig('24_cluster_AE.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f2574-527b-4b95-a83c-4d64bfd119f9",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a59cb-a41d-4323-8fc9-6cca8d0d14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder():\n",
    "    input_img = keras.Input(shape=(SHAPE[0],SHAPE[1],SHAPE[2]))\n",
    "    # init= tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.02)\n",
    "    x = keras.layers.Conv2D(64, 5, padding='same',strides=(2,2))(input_img)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    for filters in [128,194,256,512]:\n",
    "        x = keras.layers.Conv2D(filters, (3, 3), strides=(2,2), padding='same')(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.LeakyReLU()(x)\n",
    "        x = keras.layers.Conv2D(filters, (3, 3), strides=(1,1), padding='same')(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    shape_before_flattening = K.int_shape(x)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(units=latent_dim, activation='linear')(x)\n",
    "    encoder_output = keras.layers.BatchNormalization()(x)\n",
    "    # x = keras.layers.Dense(np.prod(shape_before_flattening[1:]),activation='tanh')(encoder_output)\n",
    "    x = keras.layers.Reshape((8,8,16))(x)\n",
    "\n",
    "    for filters in [512,256,194,128,64]:\n",
    "        x = keras.layers.Conv2DTranspose(filters, (3, 3), padding='same', use_bias=False, strides=(2,2))(x)\n",
    "        x = keras.layers.BatchNormalization(momentum=0.5)(x)\n",
    "        x = keras.layers.LeakyReLU()(x)\n",
    "    decoded = keras.layers.Conv2D(SHAPE[2], 3, padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    encoder = keras.models.Model(input_img, encoder_output, name='enc')\n",
    "    autoencoder = keras.models.Model(input_img, decoded, name='AE')\n",
    "    return encoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d9cd5-e737-49fc-ac33-09aed1c362aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, autoencoder = create_autoencoder()\n",
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed2200-3547-4567-b424-bc3555674121",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=tf.optimizers.Adam(),loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "# model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=15, min_delta = 0.01, mode='max', restore_best_weights=True)\n",
    "autoencoder.fit(ds_series.batch(BATCH_SIZE,drop_remainder=True).prefetch(AUTOTUNE), epochs=EPOCHS) #, callbacks=[model_early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ca3bc-a948-439d-98bd-de3b1d10cf68",
   "metadata": {},
   "source": [
    "#### Save and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2b40e-3c34-4e1e-a356-c388b6a453f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = os.path.join(weights_folder,\"ae_weights_bce\")\n",
    "if not os.path.isdir(weights_dir):\n",
    "    os.makedirs(weights_dir, exist_ok=True)\n",
    "encoder.save(os.path.join(weights_dir,\"enc_weights.h5\"))\n",
    "autoencoder.save(os.path.join(weights_dir,\"ae_weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0649d4-393d-471a-803f-75d1812e33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.models.load_model(os.path.join(weights_dir,\"enc_weights.h5\"))\n",
    "# ae = tf.keras.models.load_model(os.path.join(weights_dir,\"ae_weights.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3285a7a1-c610-48d6-92a5-89c55aa14f71",
   "metadata": {},
   "source": [
    "#### Get Latent Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b94823-a26b-4c8a-ba36-b1d49da3792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(filename,channels=SHAPE[2]):\n",
    "    image = skimage.io.imread(filename)[:,:,:channels]\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image,SHAPE[0], SHAPE[1])\n",
    "    return tf.math.divide(tf.math.add(image,tf.math.abs(tf.math.reduce_min(image))),tf.math.add(tf.math.reduce_max(image),tf.math.abs(tf.math.reduce_min(image)))+0.00001)\n",
    "\n",
    "def graph_forward(model, x):\n",
    "    return model(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d835aa-b19c-453f-a8f5-06c487d9fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = {}\n",
    "for file in tqdm(random.sample(files,2000)):\n",
    "    latent_vectors[file] = np.asarray(graph_forward(encoder, np.expand_dims(parse_image(file),0))).reshape((latent_dim,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebab5cb-986b-443d-ae86-55ca7f5591d7",
   "metadata": {},
   "source": [
    "#### Visualizing Individual Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37e5e5-a2c6-4c6b-b85e-0f64618be086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = [x[0] for i,x in enumerate(ds_series.take(10).as_numpy_iterator())]\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(len(images),2,figsize=(10,25))\n",
    "# for i,img in enumerate(images):\n",
    "#     ax[i,0].imshow(img[:,:,:3]);\n",
    "#     pred = ((graph_forward(autoencoder, np.expand_dims(img,0))[0,:,:,:3]).numpy()*255).astype('uint8')\n",
    "#     ax[i,1].imshow(pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27107801-e616-4bbf-9fc0-93e761699242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(parse_image(r\"\"\\ # insert path to test image\n",
    "#                        ,3));\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c690c0f-8ddb-4c0e-b5fb-e44b16a4dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locs = [x for x in range(latent_dim)]\n",
    "# plt.figure(figsize=(10,1))\n",
    "# plt.bar(locs,list(graph_forward(encoder, np.expand_dims(parse_image(r\"\" \\ # insert path to test image\n",
    "#    ),0)).numpy().flatten()));\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3086d3-16b1-4ff5-a42e-3a2a8dcd0354",
   "metadata": {},
   "source": [
    "#### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c41788-f529-4594-a70e-6fbc0140a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "keys = list(latent_vectors.keys())\n",
    "random.shuffle(keys)\n",
    "shuffled_vectors = {key: latent_vectors[key] for key in keys}\n",
    "shuffled_vectors = dict(itertools.islice(shuffled_vectors.items(), 2000))\n",
    "tsne = TSNE(n_components=2, learning_rate=200, perplexity=50, angle=0.5, verbose=0, init='pca').fit_transform(np.asarray(list(shuffled_vectors.values())))\n",
    "tx, ty = tsne[:,0], tsne[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c5db8-2293-4817-9f2c-e0068bc00ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 4000\n",
    "height = 3000\n",
    "max_dim = 100\n",
    "\n",
    "full_image = Image.new('RGBA', (width, height))\n",
    "for img, x, y in zip(list(shuffled_vectors.keys()), tx, ty):\n",
    "    tile = Image.fromarray((parse_image(img,3).numpy()*255).astype('uint8'))\n",
    "    rs = max(1, tile.width/max_dim, tile.height/max_dim)\n",
    "    tile = tile.resize((int(tile.width/rs), int(tile.height/rs)), Image.ANTIALIAS)\n",
    "    full_image.paste(tile, (int((width-max_dim)*x), int((height-max_dim)*y)), mask=tile.convert('RGBA'))\n",
    "\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.imshow(full_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817c9a1-1ce8-479e-863c-d7ed4be335e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image.save('tSNE_1000_images_latentx3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd829049-e905-4b8d-b704-e76bea545c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterfairy\n",
    "import rasterfairy\n",
    "\n",
    "# nx * ny = 1000, the number of images\n",
    "nx = 50\n",
    "ny = 40\n",
    "\n",
    "# assign to grid\n",
    "grid_assignment = rasterfairy.transformPointCloud2D(tsne, target=(nx, ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72232bb3-c1ce-49f6-b0ea-baa5177d3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_width = 72\n",
    "tile_height = 56\n",
    "\n",
    "full_width = tile_width * nx\n",
    "full_height = tile_height * ny\n",
    "aspect_ratio = float(tile_width) / tile_height\n",
    "\n",
    "grid_image = Image.new('RGB', (full_width, full_height))\n",
    "\n",
    "for img, grid_pos in zip(list(shuffled_vectors.keys()), grid_assignment[0]):\n",
    "    idx_x, idx_y = grid_pos\n",
    "    x, y = tile_width * idx_x, tile_height * idx_y\n",
    "    tile = Image.fromarray((parse_image(img,3).numpy()*255).astype('uint8'))\n",
    "    tile_ar = float(tile.width) / tile.height  # center-crop the tile to match aspect_ratio\n",
    "    if (tile_ar > aspect_ratio):\n",
    "        margin = 0.5 * (tile.width - aspect_ratio * tile.height)\n",
    "        tile = tile.crop((margin, 0, margin + aspect_ratio * tile.height, tile.height))\n",
    "    else:\n",
    "        margin = 0.5 * (tile.height - float(tile.width) / aspect_ratio)\n",
    "        tile = tile.crop((0, margin, tile.width, margin + float(tile.width) / aspect_ratio))\n",
    "    tile = tile.resize((tile_width, tile_height), Image.ANTIALIAS)\n",
    "    grid_image.paste(tile, (int(x), int(y)))\n",
    "\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.imshow(grid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab8723-c283-418a-872f-85b78c3f2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_image.save('grid_image_2000x3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a125ebe-9866-489d-bad4-4ce96dcf6a97",
   "metadata": {},
   "source": [
    "#### Kmeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed697c-8c9f-417d-ba13-35acd915ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(filename):\n",
    "    image = skimage.io.imread(filename)[:,:,:SHAPE[2]]\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image,SHAPE[0], SHAPE[1])\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    return tf.math.divide(tf.math.add(image,tf.math.abs(tf.math.reduce_min(image))),tf.math.add(tf.math.reduce_max(image),tf.math.abs(tf.math.reduce_min(image)))+0.00001)\n",
    "\n",
    "def graph_forward(model, x):\n",
    "    return model(x, training=False)\n",
    "\n",
    "latent_vectors = []\n",
    "for file in tqdm(files):\n",
    "    latent_vectors.append(np.asarray(graph_forward(encoder, np.expand_dims(parse_image(file),0))).reshape((latent_dim,)))\n",
    "latent_vectors = np.asarray(latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c351a28-487b-4636-aadf-ecbdf6b63b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS, -1, 1)\n",
    "compactness, labels, _ = cv2.kmeans(latent_vectors, num_classes, None, criteria, 100, cv2.KMEANS_PP_CENTERS)\n",
    "average_distance_from_each_label_center = compactness / float(len(files))\n",
    "print(average_distance_from_each_label_center)\n",
    "histo = np.histogram(labels,np.unique(labels))\n",
    "plt.bar(histo[1][1:],histo[0]);\n",
    "plt.xticks(np.unique(labels));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fa70a8-36fd-4964-a6ac-a55f11d9725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cluster_output_save_path = os.path.join(clustering_folder,\"Image Generator ww autoencoder bce 18\")\n",
    "for file,label in zip(files,labels):\n",
    "    save_dir = rf'{cluster_output_save_path}\\class_{str(label[0])}'\n",
    "    if not (os.path.exists(save_dir) and os.path.isdir(save_dir)):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    basename = os.path.basename(file)\n",
    "    shutil.copy2(file, rf'{save_dir}\\{basename}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a566d25-c8c7-483e-9e1a-8c9ba9aba469",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 3\n",
    "i = 0\n",
    "plt.figure(figsize=(17, 50))\n",
    "for col in range(num_classes):\n",
    "    class_folder = os.path.join(cluster_output_save_path,f\"class_{col}\")\n",
    "    class_files = os.listdir(class_folder)\n",
    "    random.shuffle(class_files)\n",
    "    for index in range(num_rows): \n",
    "        try:\n",
    "            img = skimage.io.imread(os.path.join(cluster_output_save_path,f\"class_{col}\",class_files[index]))\n",
    "            nat = np.stack([img[:,:,0],img[:,:,1],img[:,:,2]],axis=-1)\n",
    "            cir = np.stack([img[:,:,3],img[:,:,0],img[:,:,1]],axis=-1)\n",
    "            swir = np.stack([img[:,:,5],img[:,:,4],img[:,:,0]],axis=-1)\n",
    "            ax = plt.subplot(num_classes, num_rows*3, i + 1)\n",
    "            plt.imshow(nat,aspect=\"auto\")\n",
    "            plt.axis(\"off\")\n",
    "            ax = plt.subplot(num_classes, num_rows*3, i + 2)\n",
    "            plt.imshow(cir,aspect=\"auto\")\n",
    "            plt.axis(\"off\")\n",
    "            ax = plt.subplot(num_classes, num_rows*3, i + 3)\n",
    "            plt.imshow(swir,aspect=\"auto\")\n",
    "            plt.axis(\"off\")\n",
    "            i+=3\n",
    "        except:\n",
    "            pass\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('30_cluster_AE_combo_5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e7473-75db-4a2f-b44b-d823b8162fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 13\n",
    "plt.figure(figsize=(20, 30))\n",
    "for col in range(num_classes):\n",
    "    class_folder = os.path.join(cluster_output_save_path,f\"class_{col}\")\n",
    "    class_files = os.listdir(class_folder)\n",
    "    random.shuffle(class_files)\n",
    "    for i in range(num_rows): \n",
    "        try:\n",
    "            img = skimage.io.imread(os.path.join(cluster_output_save_path,f\"class_{col}\",class_files[i]))[:,:,:3]\n",
    "            ax = plt.subplot(num_classes, num_rows, col*num_rows + i + 1)\n",
    "            plt.imshow(img,aspect=\"auto\")\n",
    "            plt.axis(\"off\")\n",
    "        except:\n",
    "            pass\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.01)\n",
    "plt.savefig('30_cluster_AE_5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b8782-5871-4f3c-a64b-ee87d74659ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(cluster_output_save_path):\n",
    "    for file in os.listdir(os.path.join(cluster_output_save_path,folder)):\n",
    "        filename = os.path.join(cluster_output_save_path,folder,file)\n",
    "        image = Image.fromarray(skimage.io.imread(filename)[:,:,:3])\n",
    "        outname = os.path.basename(filename[:-9])\n",
    "        image.save(os.path.join(cluster_output_save_path,folder,f'{outname}.jpg'))\n",
    "        os.remove(filename)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m86"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
