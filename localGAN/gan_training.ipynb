{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "tf.__version__\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_settings import GAN, Generator, Discriminator\n",
    "from utils import normalize_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = [476,476,3]\n",
    "\n",
    "CURRENT_EPOCH = 0\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 30\n",
    "noise_level = 3\n",
    "val_size = BATCH_SIZE*100\n",
    "\n",
    "RANDOM_SEED = 101\n",
    "random.seed(RANDOM_SEED)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "latent_dim = 512\n",
    "\n",
    "input_folder = r\"\" # Folder where GEE imagery is stored\n",
    "output_folder = r\"\" # Folder where output results will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "data_dir = pathlib.Path(input_folder)\n",
    "import_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  labels=None,\n",
    "  shuffle=True,\n",
    "  image_size=(SHAPE[0],SHAPE[1]),\n",
    "  seed=RANDOM_SEED,\n",
    "  batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "                [keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "                 keras.layers.GaussianNoise(noise_level)])\n",
    "\n",
    "train_ds = import_ds.skip(val_size).shuffle(512).map(lambda x: normalize_images(data_augmentation(x, training=True)),num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "val_ds = import_ds.take(val_size).map(lambda x: normalize_images(x)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for i,image in enumerate(train_ds.take(25)):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    img = image.numpy()[0,:,:,:]*255\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.axis(\"off\")\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = tf.random.normal([25, latent_dim])\n",
    "np.save(os.path.join(output_folder,'seed'),seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(SHAPE)\n",
    "generator.summary()\n",
    "discriminator = Discriminator(SHAPE)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.25)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.000025,beta_1=0.25)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join(output_folder, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "# checkpoint.restore(r\"\").expect_partial() # Optional checkpoint restoration function\n",
    "# seed = np.load(r\"\") # Optional seed loading step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAN(generator, discriminator, latent_dim)\n",
    "model.compile(generator_optimizer, discriminator_optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveImageCallback(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(SaveImageCallback, self).__init__()\n",
    "\n",
    "    def generate_and_save_images(self, generator, epoch, test_image):\n",
    "        epoch = epoch+1\n",
    "        predictions = generator(test_image, training=False)\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.subplot(5, 5, i+1)\n",
    "            arr = predictions[i, :, :, :]*255\n",
    "            arr = arr.numpy().astype(\"uint8\")\n",
    "            plt.imshow(arr)\n",
    "            plt.axis('off')\n",
    "        plt.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder,'image_at_epoch_{:04d}.png'.format(epoch)))\n",
    "        plt.close()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global CURRENT_EPOCH\n",
    "        global train_ds\n",
    "        CURRENT_EPOCH = epoch+1\n",
    "        self.generate_and_save_images(generator,epoch,seed)\n",
    "        noise_calc = noise_level-(noise_level*CURRENT_EPOCH/(EPOCHS))*2\n",
    "        if noise_calc <= 0:\n",
    "            noise_calc = 0\n",
    "        data_augmentation = keras.Sequential(\n",
    "                    [keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "                     keras.layers.GaussianNoise(noise_calc)])\n",
    "        train_ds = import_ds.skip(val_size).shuffle(512)\\\n",
    "                        .map(lambda x: normalize_images(data_augmentation(x, training=True)),num_parallel_calls=AUTOTUNE)\\\n",
    "                        .batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "        if CURRENT_EPOCH % 2 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=[SaveImageCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = [model.evaluate(val,verbose=0)[0][0] for val in val_ds.take(50).as_numpy_iterator()]\n",
    "# print(np.asarray(results).mean(),np.asarray(results).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(output_folder,\"gan_model.h5\"))\n",
    "generator.save(os.path.join(output_folder,\"generator_weights.h5\"))\n",
    "discriminator.save(os.path.join(output_folder,\"discriminator_weights.h5\"))\n",
    "np.save(os.path.join(output_folder,'seed'),seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generator(seed, training=False)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "# print(predictions.numpy())\n",
    "for i in range(predictions.shape[0]):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    arr = predictions[i, :, :, :]*255\n",
    "    arr = arr.numpy().astype(\"uint8\")\n",
    "    plt.imshow(arr)\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['Gen Loss'])\n",
    "plt.plot(history.history['Disc Loss'])\n",
    "plt.plot([v[0][0] for v in history.history['val_discriminator']])\n",
    "plt.title('Model Losses')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Generator', 'Discriminator','Validation'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('gan_fig.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
